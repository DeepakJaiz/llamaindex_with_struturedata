{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2455428f",
   "metadata": {},
   "source": [
    "#### First, we use SQLAlchemy to setup a simple sqlite db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c00220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, String, Integer, select, column\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\",future=True)\n",
    "metadata_obj = MetaData(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e99e2e",
   "metadata": {},
   "source": [
    "#### We then create a city_stats table: You can give any name to table you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8deebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "metadata_obj.create_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b908798",
   "metadata": {},
   "source": [
    "#### Now itâ€™s time to insert some datapoints!\n",
    "\n",
    "##### If you want to look into filling into this table by inferring structured datapoints from unstructured data, take a look at the below section. Otherwise, you can choose to directly populate this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda0821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2731571, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13929286, \"country\": \"Japan\"},\n",
    "    {\"city_name\": \"Berlin\", \"population\": 600000, \"country\": \"Germany\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.connect() as connection:\n",
    "        cursor = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b9fd8",
   "metadata": {},
   "source": [
    "#### Finally, we can wrap the SQLAlchemy engine with our SQLDatabase wrapper; this allows the db to be used within LlamaIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb29d49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71202da",
   "metadata": {},
   "source": [
    "#### Then we use the Wikipedia reader from LlamaHub to load some pages regarding the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43537de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "wiki_docs = WikipediaReader().load_data(pages=['Moscow','Toronto','Tokyo','Berlin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228a737",
   "metadata": {},
   "source": [
    "#### When we build the SQL index, we can specify these docs as the first input; these documents will be converted to structured datapoints and inserted into the db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eede1d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80a8e3c6e1ede764193aab3ab8659437 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80a8e3c6e1ede764193aab3ab8659437 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80a8e3c6e1ede764193aab3ab8659437 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 08:51:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-khwmozcildgjtplixngidrvb', 'openai-processing-ms': '293', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149744', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': '80a8e3c6e1ede764193aab3ab8659437', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc0e141c1d9a89-NAG', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 41120a9f7fb762be6b07ef13c72ebe74 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 41120a9f7fb762be6b07ef13c72ebe74 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 41120a9f7fb762be6b07ef13c72ebe74 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 08:51:23 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-khwmozcildgjtplixngidrvb', 'openai-processing-ms': '5268', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149743', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': '41120a9f7fb762be6b07ef13c72ebe74', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc0e62bb949a89-NAG', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 0e51ca29bb74d63f0a863197cce5724a in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 0e51ca29bb74d63f0a863197cce5724a in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 0e51ca29bb74d63f0a863197cce5724a in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 08:51:41 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-khwmozcildgjtplixngidrvb', 'openai-processing-ms': '257', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149743', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': '0e51ca29bb74d63f0a863197cce5724a', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc0ef77de49a89-NAG', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 3689b81f86e8f86aa31f57521bf4f54f in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 3689b81f86e8f86aa31f57521bf4f54f in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 3689b81f86e8f86aa31f57521bf4f54f in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 08:51:46 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-khwmozcildgjtplixngidrvb', 'openai-processing-ms': '273', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149744', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': '3689b81f86e8f86aa31f57521bf4f54f', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc0f1449039a89-NAG', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID f5933213395fb7253a528379d3cab402 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID f5933213395fb7253a528379d3cab402 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID f5933213395fb7253a528379d3cab402 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 08:54:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-khwmozcildgjtplixngidrvb', 'openai-processing-ms': '1355', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149743', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': 'f5933213395fb7253a528379d3cab402', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc1380ea939a89-NAG', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID fdf7d58afeed3bb4cacc52b29d738c4d in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID fdf7d58afeed3bb4cacc52b29d738c4d in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID fdf7d58afeed3bb4cacc52b29d738c4d in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 08:54:53 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-khwmozcildgjtplixngidrvb', 'openai-processing-ms': '146', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149744', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': 'fdf7d58afeed3bb4cacc52b29d738c4d', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc13a50c159a89-NAG', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 6c50fdffbe5e537be0f9fc193b102c96 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 6c50fdffbe5e537be0f9fc193b102c96 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 6c50fdffbe5e537be0f9fc193b102c96 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 08:55:03 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-khwmozcildgjtplixngidrvb', 'openai-processing-ms': '135', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149744', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': '6c50fdffbe5e537be0f9fc193b102c96', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc13e28a409a89-NAG', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n",
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\langchain\\sql_database.py:227: UserWarning: This method is deprecated - please use `get_usable_table_names`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "\n",
    "from llama_index import GPTSQLStructStoreIndex, SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\n",
    "# NOTE: the table_name specified here is the table that you\n",
    "# want to extract into from unstructured documents.\n",
    "index = GPTSQLStructStoreIndex.from_documents(\n",
    "    wiki_docs, \n",
    "    sql_database=sql_database, \n",
    "    table_name=\"city_stats\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6098e",
   "metadata": {},
   "source": [
    "#### You can take a look at the current table to verify that the datapoints have been inserted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c94adb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Moscow', 25000, 'Russia'), ('Toronto', 100000, 'Canada'), ('Tokyo', 6700000, 'Japan'), ('Berlin', 600000, 'Germany')]\n"
     ]
    }
   ],
   "source": [
    "# view current table\n",
    "stmt = select(\n",
    "    [column(\"city_name\"), column(\"population\"), column(\"country\")]\n",
    ").select_from(city_stats_table)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    results = connection.execute(stmt).fetchall()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650855c",
   "metadata": {},
   "source": [
    "#### Then ask your queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc70ae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Moscow', 25000)]\n"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Which city has the Miminum population?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "836c936a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT city_name, MIN(population) \\nFROM city_stats;'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.extra_info['sql_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07e456ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tokyo', 6700000)]\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Which city has the Maximum population?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e541f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
